# bitnet.cpp-env

# Runnning inference
```
python run_inference.py -m models/Llama3-8B-1.58-100B-tokens/ggml-model-i2_s.gguf -p "What anime is popular in Japan?\nAnswer:" -n 256 -temp 0.1
```
